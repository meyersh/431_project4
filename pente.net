FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=21 6 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (21, 5, 5.00000000000000000000e-01) (21, 5, 5.00000000000000000000e-01) (21, 5, 5.00000000000000000000e-01) (21, 5, 5.00000000000000000000e-01) (21, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (6, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.45787744522094726562e+01) (1, 1.10138885498046875000e+02) (2, -4.63483642578125000000e+02) (3, -5.70824531250000000000e+04) (4, 1.96172065734863281250e+01) (5, -4.58548393249511718750e+01) (6, 4.07248321533203125000e+02) (7, 6.88896640625000000000e+04) (8, -1.01070610046386718750e+02) (9, -1.07130508422851562500e+01) (10, -1.58334396362304687500e+02) (11, -2.54642871093750000000e+04) (12, -1.93940078735351562500e+02) (13, -1.09015426635742187500e+02) (14, 1.55021484375000000000e+02) (15, 2.86199453125000000000e+04) (16, -1.39492225646972656250e+01) (17, 3.54581909179687500000e+01) (18, -1.00368614196777343750e+02) (19, 1.40458679199218750000e+02) (20, -6.22553787231445312500e+01) (0, 9.61576766967773437500e+01) (1, -2.83590297698974609375e+01) (2, -5.59075378417968750000e+02) (3, -4.49577343750000000000e+04) (4, 1.30160354614257812500e+02) (5, -1.02147293090820312500e+02) (6, 5.61549194335937500000e+02) (7, 5.75583750000000000000e+04) (8, -3.29682235717773437500e+01) (9, 5.08302841186523437500e+01) (10, -1.06943496704101562500e+02) (11, -2.03130664062500000000e+04) (12, -1.09288307189941406250e+02) (13, 2.59536457061767578125e+00) (14, 1.72812835693359375000e+02) (15, 2.38869863281250000000e+04) (16, 1.55100128173828125000e+02) (17, -1.43188354492187500000e+02) (18, -4.72561340332031250000e+01) (19, -2.86283226013183593750e+01) (20, 8.41203880310058593750e+00) (0, -3.57292594909667968750e+01) (1, 3.65335311889648437500e+01) (2, -2.74448394775390625000e+02) (3, -5.14506289062500000000e+04) (4, 4.69790496826171875000e+01) (5, -5.30360755920410156250e+01) (6, 2.71732238769531250000e+02) (7, 6.39920664062500000000e+04) (8, 1.06450157165527343750e+02) (9, 6.85923194885253906250e+00) (10, -7.64092636108398437500e+01) (11, -2.40480742187500000000e+04) (12, 8.24184131622314453125e+00) (13, 9.17421722412109375000e+01) (14, 1.05873344421386718750e+02) (15, 2.68331328125000000000e+04) (16, 8.41691055297851562500e+01) (17, 2.62138900756835937500e+01) (18, -2.15884361267089843750e+01) (19, 5.33275108337402343750e+01) (20, 1.86618537902832031250e+01) (0, -5.62857055664062500000e+02) (1, -3.87955371093750000000e+03) (2, -5.20213718750000000000e+05) (3, -3.80434062500000000000e+05) (4, 2.02109207153320312500e+02) (5, 5.23548339843750000000e+03) (6, 5.86504437500000000000e+05) (7, 4.17577468750000000000e+05) (8, 3.69253540039062500000e+02) (9, -4.97567724609375000000e+03) (10, -2.56674500000000000000e+05) (11, -1.60110265625000000000e+05) (12, 1.03023205566406250000e+03) (13, 2.74536718750000000000e+03) (14, 2.82058531250000000000e+05) (15, 1.73556265625000000000e+05) (16, 6.17599243164062500000e+02) (17, 1.24489379882812500000e+03) (18, -1.62522473144531250000e+03) (19, 1.64334948730468750000e+03) (20, -2.84977294921875000000e+02) (0, -1.02039054870605468750e+02) (1, -3.44846000671386718750e+01) (2, -1.71264831542968750000e+02) (3, -4.89317109375000000000e+04) (4, 1.35475494384765625000e+02) (5, -1.89567352294921875000e+02) (6, 4.31027557373046875000e+02) (7, 6.02969453125000000000e+04) (8, 8.07572250366210937500e+01) (9, -2.75402488708496093750e+01) (10, -5.20494651794433593750e+01) (11, -2.21158789062500000000e+04) (12, -1.14053039550781250000e+02) (13, 8.84139099121093750000e+01) (14, 3.42210540771484375000e+01) (15, 2.49175683593750000000e+04) (16, -1.67714977264404296875e+01) (17, 9.19897766113281250000e+01) (18, 9.21816539764404296875e+00) (19, 2.52410507202148437500e+01) (20, 4.67400360107421875000e+01) (21, 1.39303674697875976562e+01) (22, 2.91786289215087890625e+00) (23, -2.92292118072509765625e+00) (24, -3.50363578796386718750e+01) (25, 2.61350393295288085938e+00) (26, -9.17353248596191406250e+00) 
